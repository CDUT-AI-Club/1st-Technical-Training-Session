{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ea9d7f",
   "metadata": {},
   "source": [
    "# Pytorch 学习\n",
    "## 一、张量\n",
    "1. ### 张量的概念： \n",
    "张量（Tensor）是 PyTorch 中的核心数据结构，用于存储和操作多维数组。\n",
    "\n",
    "2. ### 张量的属性： \n",
    "（1）张量的维度是指张量的秩，秩是指张量中元素数量的个数，一维可看做是一个数组，二维可看做矩阵，三维可看做三维空间中的点，四维可看做四维空间中的点云。 \n",
    "> .dim()  返回秩\n",
    "\n",
    "（2）张量的形状是指张量的各个维度的长度。  \n",
    "> 例如：一个3x4的矩阵，它的秩为2，形状为(3,4)。\n",
    "> print(g.shape)  返回形状\n",
    "> print(g.size())  同上\n",
    "\n",
    "（3）张量的数据类型是指张量中元素的类型,支持多种数据类型（整型、浮点型、布尔型等）  \n",
    "> 例如：一个3x4的矩阵，它的元素类型可以是整数、浮点数、布尔值等。  \n",
    "> print(g.dtype)  返回类型\n",
    "\n",
    "（3）张量的设备检查：\n",
    "> 张量可以存储在CPU或者GPU上，可以通过.device属性来查看张量所在的设备。  \n",
    "> .is_cuda  判断张量是否在GPU上\n",
    "\n",
    " (4)张量转置：\n",
    "> 张量的转置操作是指将张量的行列互换，例如一个3x4的矩阵，它的转置操作可以得到4x3的矩阵。  \n",
    "> g.t()  转置\n",
    "\n",
    "3. ### 张量的创建："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23cbb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[0.0876, 0.8373, 0.6534, 0.2927],\n",
      "        [0.3609, 0.0971, 0.6540, 0.2159],\n",
      "        [0.3262, 0.3425, 0.8255, 0.8411]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#创建张量\n",
    "x = torch.tensor([1,2,3])\n",
    "print(x)\n",
    "#创建随机张量\n",
    "c = torch.rand(3,4)\n",
    "print(c)\n",
    "#创建全零张量\n",
    "z = torch.zeros(2,3)\n",
    "print(z)\n",
    "#创建全一张量\n",
    "o = torch.ones(2,3)\n",
    "print(o)\n",
    "#创建单位矩阵\n",
    "I = torch.eye(3)\n",
    "print(I)\n",
    "#将numpy数组转换为张量\n",
    "import numpy as np\n",
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "#将张量转换为numpy数组\n",
    "c = b.numpy()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021070e6",
   "metadata": {},
   "source": [
    "4. 对张量的操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89a50c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始张量:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "【索引和切片】\n",
      "获取第一行: tensor([1., 2., 3.])\n",
      "获取第一行第一列的元素: tensor(1.)\n",
      "获取第二列的所有元素: tensor([2., 5.])\n",
      "\n",
      "【形状变换】\n",
      "改变形状后的张量:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "展平后的张量:\n",
      " tensor([1., 2., 3., 4., 5., 6.])\n",
      "\n",
      "【数学运算】\n",
      "张量加 10:\n",
      " tensor([[11., 12., 13.],\n",
      "        [14., 15., 16.]])\n",
      "张量乘 2:\n",
      " tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n",
      "张量元素的和: 21.0\n",
      "\n",
      "【与其他张量操作】\n",
      "另一个张量:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "矩阵乘法结果:\n",
      " tensor([[ 6.,  6.],\n",
      "        [15., 15.]])\n",
      "\n",
      "【条件判断和筛选】\n",
      "大于 3 的元素的布尔掩码:\n",
      " tensor([[False, False, False],\n",
      "        [ True,  True,  True]])\n",
      "大于 3 的元素:\n",
      " tensor([4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个 2D 张量\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "print(\"原始张量:\\n\", tensor)\n",
    "\n",
    "# 1. **索引和切片操作**\n",
    "print(\"\\n【索引和切片】\")\n",
    "print(\"获取第一行:\", tensor[0])\n",
    "print(\"获取第一行第一列的元素:\", tensor[0, 0]) \n",
    "print(\"获取第二列的所有元素:\", tensor[:, 1]) \n",
    "\n",
    "# 2. **形状变换操作**\n",
    "print(\"\\n【形状变换】\")\n",
    "reshaped = tensor.view(3, 2) \n",
    "print(\"改变形状后的张量:\\n\", reshaped)\n",
    "flattened = tensor.flatten() \n",
    "print(\"展平后的张量:\\n\", flattened)\n",
    "\n",
    "# 3. **数学运算操作**\n",
    "print(\"\\n【数学运算】\")\n",
    "tensor_add = tensor + 10 \n",
    "print(\"张量加 10:\\n\", tensor_add)\n",
    "tensor_mul = tensor * 2 \n",
    "print(\"张量乘 2:\\n\", tensor_mul)\n",
    "tensor_sum = tensor.sum() \n",
    "print(\"张量元素的和:\", tensor_sum.item())\n",
    "\n",
    "# 4. **与其他张量的操作**\n",
    "print(\"\\n【与其他张量操作】\")\n",
    "tensor2 = torch.tensor([[1, 1, 1], [1, 1, 1]], dtype=torch.float32)\n",
    "print(\"另一个张量:\\n\", tensor2)\n",
    "tensor_dot = torch.matmul(tensor, tensor2.T) \n",
    "print(\"矩阵乘法结果:\\n\", tensor_dot)\n",
    "\n",
    "# 5. **条件判断和筛选**\n",
    "print(\"\\n【条件判断和筛选】\")\n",
    "mask = tensor > 3 \n",
    "print(\"大于 3 的元素的布尔掩码:\\n\", mask)\n",
    "filtered_tensor = tensor[tensor > 3] \n",
    "print(\"大于 3 的元素:\\n\", filtered_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d377683",
   "metadata": {},
   "source": [
    "5. 张量的GPU加速\n",
    "> 将张量转移到GPU上进行加速运算，可以显著提升运算速度\n",
    "> 检查GPU是否可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1e8ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#转移\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.tensor([1.0, 2.0, 3.0], device=device)\n",
    "\n",
    "#检查\n",
    "torch.cuda.is_available() #返回布尔值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56769e8a",
   "metadata": {},
   "source": [
    "6. 梯度与自动微分\n",
    "张量支持自动微分，可自动计算梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba1c15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个需要梯度的张量\n",
    "tensor_requires_grad = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# 进行一些操作\n",
    "tensor_result = tensor_requires_grad * 2\n",
    "\n",
    "# 计算梯度\n",
    "tensor_result.backward()\n",
    "print(tensor_requires_grad.grad)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189097ca",
   "metadata": {},
   "source": [
    "7. 自动求导\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b3ed65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5942, -0.6803],\n",
      "        [ 0.1916, -1.2811]], requires_grad=True)\n",
      "tensor(10.3438, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个需要计算梯度的张量\n",
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e1b01",
   "metadata": {},
   "source": [
    "##二、神经网络基础    \n",
    "###1. 创建简单的神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a20e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义一个简单的全连接神经网络\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 2)  # 输入层到隐藏层\n",
    "        self.fc2 = nn.Linear(2, 1)  # 隐藏层到输出层\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # ReLU 激活函数\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 创建网络实例\n",
    "model = SimpleNN()\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478caaf",
   "metadata": {},
   "source": [
    "###2. 第一个神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51eeb8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss:  0.24839134514331818\n",
      "epoch:  1 loss:  0.24821177124977112\n",
      "epoch:  2 loss:  0.24803271889686584\n",
      "epoch:  3 loss:  0.2478541135787964\n",
      "epoch:  4 loss:  0.24767610430717468\n",
      "epoch:  5 loss:  0.24749855697155\n",
      "epoch:  6 loss:  0.24732151627540588\n",
      "epoch:  7 loss:  0.2471449375152588\n",
      "epoch:  8 loss:  0.24696889519691467\n",
      "epoch:  9 loss:  0.24679331481456757\n",
      "epoch:  10 loss:  0.24661822617053986\n",
      "epoch:  11 loss:  0.24644359946250916\n",
      "epoch:  12 loss:  0.24626943469047546\n",
      "epoch:  13 loss:  0.24609582126140594\n",
      "epoch:  14 loss:  0.24592263996601105\n",
      "epoch:  15 loss:  0.24574990570545197\n",
      "epoch:  16 loss:  0.2455776184797287\n",
      "epoch:  17 loss:  0.24540583789348602\n",
      "epoch:  18 loss:  0.2452344447374344\n",
      "epoch:  19 loss:  0.24506357312202454\n",
      "epoch:  20 loss:  0.2448931187391281\n",
      "epoch:  21 loss:  0.24472308158874512\n",
      "epoch:  22 loss:  0.2445535659790039\n",
      "epoch:  23 loss:  0.24438443779945374\n",
      "epoch:  24 loss:  0.244215726852417\n",
      "epoch:  25 loss:  0.24404747784137726\n",
      "epoch:  26 loss:  0.24387963116168976\n",
      "epoch:  27 loss:  0.24371223151683807\n",
      "epoch:  28 loss:  0.243545264005661\n",
      "epoch:  29 loss:  0.24337871372699738\n",
      "epoch:  30 loss:  0.2432125359773636\n",
      "epoch:  31 loss:  0.24304679036140442\n",
      "epoch:  32 loss:  0.24288146197795868\n",
      "epoch:  33 loss:  0.24271652102470398\n",
      "epoch:  34 loss:  0.2425519973039627\n",
      "epoch:  35 loss:  0.24238789081573486\n",
      "epoch:  36 loss:  0.24222418665885925\n",
      "epoch:  37 loss:  0.2420608103275299\n",
      "epoch:  38 loss:  0.24189786612987518\n",
      "epoch:  39 loss:  0.2417353093624115\n",
      "epoch:  40 loss:  0.24157316982746124\n",
      "epoch:  41 loss:  0.24141135811805725\n",
      "epoch:  42 loss:  0.2412499487400055\n",
      "epoch:  43 loss:  0.24108891189098358\n",
      "epoch:  44 loss:  0.24092824757099152\n",
      "epoch:  45 loss:  0.2407679557800293\n",
      "epoch:  46 loss:  0.24060800671577454\n",
      "epoch:  47 loss:  0.24044843018054962\n",
      "epoch:  48 loss:  0.24028924107551575\n",
      "epoch:  49 loss:  0.24013037979602814\n"
     ]
    }
   ],
   "source": [
    "# 导入PyTorch库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义输入层大小、隐藏层大小、输出层大小和批量大小\n",
    "n_in, n_h, n_out, batch_size = 10, 5, 1, 10\n",
    "\n",
    "# 创建虚拟输入数据和目标数据\n",
    "x = torch.randn(batch_size, n_in)  # 随机生成输入数据\n",
    "y = torch.tensor([[1.0], [0.0], [0.0],\n",
    "                 [1.0], [1.0], [1.0], [0.0], [0.0], [1.0], [1.0]])  # 目标输出数据\n",
    "\n",
    "# 创建顺序模型，包含线性层、ReLU激活函数和Sigmoid激活函数\n",
    "model = nn.Sequential(\n",
    "   nn.Linear(n_in, n_h),  # 输入层到隐藏层的线性变换\n",
    "   nn.ReLU(),            # 隐藏层的ReLU激活函数\n",
    "   nn.Linear(n_h, n_out),  # 隐藏层到输出层的线性变换\n",
    "   nn.Sigmoid()           # 输出层的Sigmoid激活函数\n",
    ")\n",
    "\n",
    "# 定义均方误差损失函数和随机梯度下降优化器\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # 学习率为0.01\n",
    "\n",
    "# 执行梯度下降算法进行模型训练\n",
    "for epoch in range(50):  # 迭代50次\n",
    "   y_pred = model(x)  # 前向传播，计算预测值\n",
    "   loss = criterion(y_pred, y)  # 计算损失\n",
    "   print('epoch: ', epoch, 'loss: ', loss.item())  # 打印损失值\n",
    "\n",
    "   optimizer.zero_grad()  # 清零梯度\n",
    "   loss.backward()  # 反向传播，计算梯度\n",
    "   optimizer.step()  # 更新模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2524f789",
   "metadata": {},
   "source": [
    "##三、数据处理与加载\n",
    "###1. 自定义Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bda03689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 自定义数据集类\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X_data, Y_data):\n",
    "        self.X_data = X_data\n",
    "        self.Y_data = Y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集的大小\"\"\"\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"返回指定索引的数据\"\"\"\n",
    "        x = torch.tensor(self.X_data[idx], dtype=torch.float32) # 转换为 Tensor\n",
    "        y = torch.tensor(self.Y_data[idx], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# 示例数据\n",
    "X_data = [[1, 2], [3, 4], [5, 6], [7, 8]] # 输入特征\n",
    "Y_data = [1, 0, 1, 0] # 目标标签\n",
    "\n",
    "# 创建数据集实例\n",
    "dataset = MyDataset(X_data, Y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b8baf",
   "metadata": {},
   "source": [
    "###2. DataLoader 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b53bfed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Inputs: tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "Labels: tensor([0., 1.])\n",
      "Batch 2:\n",
      "Inputs: tensor([[1., 2.],\n",
      "        [7., 8.]])\n",
      "Labels: tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 创建 DataLoader 实例，batch_size 设置每次加载的样本数量\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 打印加载的数据\n",
    "for epoch in range(1):\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        print(f'Batch {batch_idx + 1}:')\n",
    "        print(f'Inputs: {inputs}')\n",
    "        print(f'Labels: {labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679636d3",
   "metadata": {},
   "source": [
    "##四、数据集\n",
    "###1. Dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a91939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小: 100\n",
      "第 0 个样本: (tensor([ 0.1774, -0.5163, -1.4653,  0.9251, -0.0267]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 自定义数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        # 数据初始化\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回数据集大小\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 按索引返回数据和标签\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label\n",
    "\n",
    "# 生成示例数据\n",
    "data = torch.randn(100, 5)  # 100 个样本，每个样本有 5 个特征\n",
    "labels = torch.randint(0, 2, (100,))  # 100 个标签，取值为 0 或 1\n",
    "\n",
    "# 实例化数据集\n",
    "dataset = MyDataset(data, labels)\n",
    "\n",
    "# 测试数据集\n",
    "print(\"数据集大小:\", len(dataset))\n",
    "print(\"第 0 个样本:\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c1f654",
   "metadata": {},
   "source": [
    "###2. DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b9c4ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1\n",
      "数据: tensor([[ 0.3995, -0.2506,  1.2575,  1.4829, -0.4648],\n",
      "        [-0.9211,  0.9862, -0.8771, -0.5299,  0.2593],\n",
      "        [ 0.6533,  2.1652, -0.5321,  0.1677,  0.2277],\n",
      "        [ 1.7109,  1.6551, -0.4611, -0.5387,  0.1038],\n",
      "        [ 1.1513,  0.7928, -1.0680, -1.5302, -0.6365],\n",
      "        [ 0.2114, -0.2996, -0.0025,  0.7946,  0.3224],\n",
      "        [-0.6230, -0.5963, -1.1038,  1.1768,  1.5314],\n",
      "        [-0.0418,  0.7482,  0.0982, -1.0948,  1.3369],\n",
      "        [-0.5062,  1.0496,  0.1247,  0.0111,  1.7290],\n",
      "        [-0.2552, -0.6193,  0.5204, -1.6448,  0.0638]])\n",
      "标签: tensor([0, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "批次 2\n",
      "数据: tensor([[-2.1926, -1.0206,  0.2850, -0.2766, -1.8185],\n",
      "        [ 0.4735, -1.0229, -0.1064,  0.4118, -0.2687],\n",
      "        [-1.3911, -2.0342, -1.5711,  1.4035, -0.3321],\n",
      "        [-0.6951,  0.0629,  0.9292, -0.6653, -1.0978],\n",
      "        [-0.2986, -0.6654, -0.6392,  0.2306, -0.6792],\n",
      "        [ 0.5365, -0.3769, -0.2262,  0.3272, -1.2582],\n",
      "        [ 1.7093,  0.2828,  1.4366, -1.4886, -0.1768],\n",
      "        [ 0.4731,  0.3289, -0.5773, -1.0654, -2.0365],\n",
      "        [-1.6690, -0.7345, -1.7839,  1.6946, -0.5498],\n",
      "        [-0.3122, -1.2504, -0.5092, -0.4964,  0.7040]])\n",
      "标签: tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 0])\n",
      "批次 3\n",
      "数据: tensor([[-0.0697,  0.5170,  1.8975, -1.0850, -0.2257],\n",
      "        [-0.1243,  0.0935,  0.0860,  0.0367, -0.6434],\n",
      "        [-1.4098,  0.6977,  0.3080, -0.2487, -0.6834],\n",
      "        [ 0.0306,  0.6437, -0.7936,  2.1300, -0.0426],\n",
      "        [-0.5357, -1.2711, -1.2508, -0.2470, -0.4248],\n",
      "        [ 0.2006,  1.5859,  1.3028,  1.8432,  0.6154],\n",
      "        [-1.8595,  0.5678,  0.3983, -0.2262,  1.1617],\n",
      "        [-3.7132,  0.5936, -0.4185,  0.7915, -0.1272],\n",
      "        [ 0.9910,  0.0961, -0.9758, -2.2268,  1.1313],\n",
      "        [ 1.7290, -0.6597, -0.1451,  0.6856,  1.1835]])\n",
      "标签: tensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 自定义数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        # 数据初始化\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回数据集大小\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 按索引返回数据和标签\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label\n",
    "\n",
    "# 生成示例数据\n",
    "data = torch.randn(100, 5)  # 100 个样本，每个样本有 5 个特征\n",
    "labels = torch.randint(0, 2, (100,))  # 100 个标签，取值为 0 或 1\n",
    "\n",
    "# 实例化数据集\n",
    "dataset = MyDataset(data, labels)\n",
    "# 实例化 DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True, num_workers=0)\n",
    "\n",
    "# 遍历 DataLoader\n",
    "for batch_idx, (batch_data, batch_labels) in enumerate(dataloader):\n",
    "    print(f\"批次 {batch_idx + 1}\")\n",
    "    print(\"数据:\", batch_data)\n",
    "    print(\"标签:\", batch_labels)\n",
    "    if batch_idx == 2:  # 仅显示前 3 个批次\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1837b3",
   "metadata": {},
   "source": [
    "###3. 内置数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aa1049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "批次图像大小: torch.Size([32, 1, 28, 28])\n",
      "批次标签: tensor([7, 6, 2, 1, 0, 3, 8, 8, 2, 3, 6, 3, 5, 0, 5, 8, 8, 5, 6, 1, 9, 7, 6, 5,\n",
      "        0, 6, 5, 1, 3, 0, 5, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 定义数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 转换为张量\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 标准化\n",
    "])\n",
    "\n",
    "# 加载训练数据集\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# 使用 DataLoader 加载数据\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 查看一个批次的数据\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "print(f\"批次图像大小: {images.shape}\")  # 输出形状为 [batch_size, 1, 28, 28]\n",
    "print(f\"批次标签: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce476be",
   "metadata": {},
   "source": [
    "##五、数据转换\n",
    "###对图像数据集应用转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ab174ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像张量大小: torch.Size([32, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 定义转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# 使用 DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 查看转换后的数据\n",
    "for images, labels in train_loader:\n",
    "    print(\"图像张量大小:\", images.size())  # [batch_size, 1, 128, 128]\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lvpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
